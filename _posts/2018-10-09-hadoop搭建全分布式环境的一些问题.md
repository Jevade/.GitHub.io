---
layout:     post
title:      hadoop
category: blog
description: hadoop 配置的问题
tag:hadoop ,linux
---
# 全分布式的hadoop环境的搭建
在搭建中设计到的几个文件如下
1. hadoop-env.sh
	   在脚本中配置JAVA_HOME的路径_
2. hdfs-site.xml
	   在文件中配置dfs的冗余度和权限设置，冗余度最多为3，一般和节点数一样
3. core-site.xml
	配饰fs.defaultFS ,一般为hdfs://\<hostname\>:9000
	配置hadoop.tmp.dir ,hadoop临时文件存储的地方，默认在/tmp目录下，需要更改到其他适合的目录。
4. maprep-site.xml
5. yarn-site.xml
	 配置yarn主节点的位置，以及nodemanage执行任务的方式
6. slaves
	 配置集群中的slave，只需要把slave节点的host写入就可以了
	 比如/etc/hosts 里面如下：
	1.1.1.0 master
	1.1.1.1 slave1
	1.1.1.2 slave2
则slave中配置为：
	slave1
	slave2

# 出现的问题
1. yarn-site.xml配置有问题
在主节点上使用start-all.sh启动集群
2. 防火墙没有关


	 



